{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30caeab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVID-19 Classification using CNN:\n",
    "# - In this Python script, we leverage a Convolutional Neural Network (CNN) to classify chest X-ray or CT scan images into three categories: Covid, Normal, and Viral Pneumonia.\n",
    "\n",
    "# Steps in the process:\n",
    "# 1. Dataset Collection: Gather a dataset of chest images, categorized into Covid, Normal, and Viral Pneumonia cases.\n",
    "\n",
    "# 2. Model Architecture: Design a CNN model that includes convolutional layers for feature extraction, pooling layers for downsampling, fully connected layers for classification, and ReLU activation for non-linearity.\n",
    "\n",
    "# 3. Data Preprocessing: Preprocess the images by resizing them, normalizing pixel values, and possibly augmenting the dataset for increased diversity.\n",
    "\n",
    "# 4. Data Splitting: Split the dataset into training and testing sets to evaluate the model's performance.\n",
    "\n",
    "# 5. Label Encoding: One-hot encode the class labels, representing each category as a binary vector.\n",
    "\n",
    "# 6. Model Training: Train the CNN model on the training data, monitoring its performance on the testing data. Performance metrics like accuracy, precision, recall, and F1-score are used for evaluation.\n",
    "\n",
    "# 7. Validation: Ensure the model's performance with real-world medical data to verify its accuracy, effectiveness, and safety.\n",
    "\n",
    "# The application of CNNs for COVID-19 classification is significant in early detection and diagnosis, especially in cases with limited medical resources. It also serves as a valuable tool for research, analysis, and decision support in the medical field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571a911-94a3-4aad-82a0-1d4252efb9d2",
   "metadata": {},
   "source": [
    "### 1. Importing Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a2f781-349a-4366-9771-00c5bf390efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Flatten,MaxPool2D,Dropout,Conv2D,InputLayer\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b309b1-9015-4287-8dcf-116539c91c03",
   "metadata": {},
   "source": [
    "### 2. Import the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04eea72a-6c4d-4885-9da2-e26c41866304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path for the training data.\n",
    "train_dir = \"Covid19-dataset/train/\"\n",
    "\n",
    "# Define the directory path for the testing data.\n",
    "test_dir = \"Covid19-dataset/test/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66dae955-9536-48c0-9007-441b6d31a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories (classes) your model will classify data into.\n",
    "categories = ['Covid', 'Normal', 'Viral Pneumonia']\n",
    "\n",
    "# Initialize empty lists for storing your data and labels.\n",
    "y = []  # Combined labels\n",
    "x = []  # Combined data\n",
    "\n",
    "# Set the batch size for training your model. Batch size determines how many data samples are processed in each iteration.\n",
    "Batch_Size = 32\n",
    "\n",
    "# Set the initial learning rate for your model. Learning rate affects the step size in training algorithms.\n",
    "INIT_LR = 1e-4\n",
    "\n",
    "# Define the number of epochs. An epoch is one complete pass through the entire training dataset.\n",
    "EPOCHES = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ac365-6243-4866-9ee3-9e4ed7dcb8f4",
   "metadata": {},
   "source": [
    "### 3. Reading Images from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac8f175-794b-4f83-8cdf-4430fc986ba8",
   "metadata": {},
   "source": [
    "#### 3.1 Reading The Images From The Train Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd67ae1-c2ba-49e4-b1a0-44728007f739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806\n",
      "1375\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Import the OpenCV library.\n",
    "import cv2\n",
    "\n",
    "# Read an image from the specified file path.\n",
    "im = cv2.imread('Covid19-dataset/train/Covid/COVID-00013b.jpg')\n",
    "\n",
    "# Get the dimensions of the image: width (w), height (h), and number of color channels (c).\n",
    "h, w, c = im.shape\n",
    "\n",
    "# Print the width of the image.\n",
    "print(w)\n",
    "\n",
    "# Print the height of the image.\n",
    "print(h)\n",
    "\n",
    "# Print the number of color channels (e.g., 3 for RGB images).\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3b619c1-6865-431d-8607-e8101d12965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the defined categories (e.g., 'Covid', 'Normal', 'Viral Pneumonia').\n",
    "for category in categories:\n",
    "    # Create the full path to the directory for the current category within the training directory.\n",
    "    path = os.path.join(train_dir, category)\n",
    "    \n",
    "    # Iterate through the files in the current category directory.\n",
    "    for img in os.listdir(path):\n",
    "        # Create the full path to the current image file.\n",
    "        img_path = os.path.join(path, img)\n",
    "        \n",
    "        # Read the image using OpenCV.\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        # Resize the image to a common size (e.g., 500x500 pixels).\n",
    "        image = cv2.resize(image, (500, 500))\n",
    "        \n",
    "        # Normalize the image pixel values to be in the range [0, 1].\n",
    "        image = image / 255.0\n",
    "        \n",
    "        # Append the preprocessed image to the data list (x).\n",
    "        x.append(image)\n",
    "        \n",
    "        # Append the corresponding category label to the labels list (y).\n",
    "        y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9804aa88-7855-4ed2-9e19-2633c0ed4724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        ...,\n",
       "        [0.05098039, 0.05098039, 0.05098039],\n",
       "        [0.05882353, 0.05882353, 0.05882353],\n",
       "        [0.05098039, 0.05098039, 0.05098039]],\n",
       "\n",
       "       [[0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        ...,\n",
       "        [0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.05098039, 0.05098039, 0.05098039],\n",
       "        [0.05490196, 0.05490196, 0.05490196]],\n",
       "\n",
       "       [[0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.02352941, 0.02352941, 0.02352941],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.05098039, 0.05098039, 0.05098039]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17342bfe-0803-44bf-b90d-5d2458414877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Covid', 'Covid', 'Covid', 'Covid', 'Covid']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c05445-e88e-4736-8f73-2baee647e158",
   "metadata": {},
   "source": [
    "#### 3.1. Reading The Images From The Test Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de33f0b-501b-4839-ba19-dcaf3c3be7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the defined categories (e.g., 'Covid', 'Normal', 'Viral Pneumonia').\n",
    "for category in categories:\n",
    "    # Create the full path to the directory for the current category within the testing directory.\n",
    "    path = os.path.join(test_dir, category)\n",
    "    \n",
    "    # Iterate through the files in the current category directory.\n",
    "    for img in os.listdir(path):\n",
    "        # Create the full path to the current image file.\n",
    "        img_path = os.path.join(path, img)\n",
    "        \n",
    "        # Read the image using OpenCV.\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        # Resize the image to a common size (e.g., 500x500 pixels).\n",
    "        image = cv2.resize(image, (500, 500))\n",
    "        \n",
    "        # Normalize the image pixel values to be in the range [0, 1].\n",
    "        image = image / 255.0\n",
    "        \n",
    "        # Append the preprocessed image to the data list (x).\n",
    "        x.append(image)\n",
    "        \n",
    "        # Append the corresponding category label to the labels list (y).\n",
    "        y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cb3c1ed-a149-404e-8721-d804eb41f484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        ...,\n",
       "        [0.05098039, 0.05098039, 0.05098039],\n",
       "        [0.05882353, 0.05882353, 0.05882353],\n",
       "        [0.05098039, 0.05098039, 0.05098039]],\n",
       "\n",
       "       [[0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        ...,\n",
       "        [0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.05098039, 0.05098039, 0.05098039],\n",
       "        [0.05490196, 0.05490196, 0.05490196]],\n",
       "\n",
       "       [[0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.02352941, 0.02352941, 0.02352941],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03529412, 0.03529412, 0.03529412],\n",
       "        [0.05098039, 0.05098039, 0.05098039]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098],\n",
       "        [0.02745098, 0.02745098, 0.02745098]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255],\n",
       "        [0.03137255, 0.03137255, 0.03137255]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4577377-753e-48e8-a03f-c22915a1fd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Covid', 'Covid', 'Covid', 'Covid', 'Covid']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2933913-8453-45d4-83bc-599b20740d2c",
   "metadata": {},
   "source": [
    "### 4. Preprocessing The Data And Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417dfc6d-3646-457b-a095-fc1d885faa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_split function from scikit-learn to split the data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets:\n",
    "# - x is the data (images).\n",
    "# - y is the labels (categories).\n",
    "# - test_size specifies the proportion of the data to be used for testing (e.g., 20%).\n",
    "# - random_state is used for reproducibility of the split.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# After this code, you'll have:\n",
    "# - x_train: Training data (images).\n",
    "# - x_test: Testing data (images).\n",
    "# - y_train: Training labels (categories).\n",
    "# - y_test: Testing labels (categories).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b89266b-6924-4e15-b27a-35eeed6b2d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding on the class labels. \n",
    "# One-hot encoding is a common technique used in machine learning for handling categorical labels. \n",
    "# It transforms categorical labels into a binary format that is suitable for use in machine learning models.\n",
    "\n",
    "# Initialize a LabelBinarizer object.\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# Fit and transform the training labels (y_train) to one-hot encoded format.\n",
    "y_train = lb.fit_transform(y_train)\n",
    "\n",
    "# Transform the testing labels (y_test) to one-hot encoded format using the same LabelBinarizer.\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "# After this code, y_train and y_test will be one-hot encoded, where each category is represented as a binary vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f4d7c91-fcad-4c23-82de-2350a60fddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### convert your data and labels to NumPy arrays and specifying the data type as 'float32'.\n",
    "#### This data type is often used in machine learning for numerical computations and is more memory-efficient compared to other data types like 'float64'\n",
    "\n",
    "x_train = np.array(x_train,dtype='float32')\n",
    "y_train = np.array(y_train,dtype='float32')\n",
    "x_test = np.array(x_test,dtype='float32')\n",
    "y_test = np.array(y_test,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40fc4cff-6429-4f48-862b-a2c50953e8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 500, 500, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "763f0d4c-b88d-4dad-8bec-140f006ee6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 500, 500, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90c10917-3bce-4de5-b5d3-f1c735e639cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f17c568a-51c0-4e4d-a700-f764a2f8b768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d29285-f75a-421e-8191-603f0d2dc81b",
   "metadata": {},
   "source": [
    "### 5. Creating the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1a5984d-6c0d-4ac7-8c4a-849f022377a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 498, 498, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 249, 249, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 247, 247, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 123, 123, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 121, 121, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 60, 60, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 460800)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               58982528  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,076,163\n",
      "Trainable params: 59,076,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model.\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with shape (500, 500, 3) representing a 500x500 pixel image with 3 color channels (RGB).\n",
    "model.add(InputLayer(input_shape=(500, 500, 3)))\n",
    "\n",
    "# Convolutional layers with increasing filter size and max-pooling.\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps for the fully connected layers.\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers with a ReLU activation function.\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add dropout for regularization to reduce overfitting.\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer with 3 units (corrected) for classification into 3 classes and softmax activation.\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Print a summary of the model architecture, showing the layers and the number of parameters.\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3890322-2662-4a60-8388-3f610fada603",
   "metadata": {},
   "source": [
    "### 6. Compiling The Model, setup the optimizer for training a  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e8c3f8c-97dd-4882-b288-baee9c167326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimizer with the specified learning rate (INIT_LR) and weight decay (INIT_LR / Batch_Size).\n",
    "opt = Adam(learning_rate=INIT_LR, weight_decay=INIT_LR / Batch_Size)\n",
    "\n",
    "# Compile the model:\n",
    "# - optimizer: The Adam optimizer with the specified learning rate and weight decay.\n",
    "# - loss: The loss function used for training. 'categorical_crossentropy' is commonly used for multi-class classification tasks.\n",
    "# - metrics: The evaluation metrics for the model. Here, accuracy is used to monitor model performance.\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b67e4",
   "metadata": {},
   "source": [
    "### 7. Training a model using the provided training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58e65f53-aebf-41d7-a44c-2deed0e238a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 40s 5s/step - loss: 1.4748 - accuracy: 0.3884\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 54s 8s/step - loss: 0.8913 - accuracy: 0.6154\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 51s 7s/step - loss: 0.7012 - accuracy: 0.7376\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 53s 8s/step - loss: 0.5645 - accuracy: 0.7964\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 44s 6s/step - loss: 0.4407 - accuracy: 0.8281\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 55s 8s/step - loss: 0.3361 - accuracy: 0.9095\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 49s 7s/step - loss: 0.2571 - accuracy: 0.8914\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 54s 8s/step - loss: 0.2383 - accuracy: 0.9276\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 66s 10s/step - loss: 0.1802 - accuracy: 0.9464\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 56s 8s/step - loss: 0.1473 - accuracy: 0.9593\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of validation steps based on the size of the testing dataset and batch size.\n",
    "validation_steps = len(y_test) // Batch_Size\n",
    "\n",
    "# Train the model using the training data and validate it using the testing data.\n",
    "# - x_train: Training data.\n",
    "# - y_train: Training labels.\n",
    "# - epochs: Number of training epochs.\n",
    "# - steps_per_epoch: The number of training steps per epoch (based on the size of the training dataset and batch size).\n",
    "# - batch_size: The size of each batch during training.\n",
    "# - validation_steps: The number of validation steps during training (based on the size of the testing dataset and batch size).\n",
    "History = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHES,\n",
    "    steps_per_epoch=len(x_train) // Batch_Size,\n",
    "    batch_size=Batch_Size,\n",
    "    validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f0fb1",
   "metadata": {},
   "source": [
    "### 8. Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "973fea94-79b5-4066-99f8-543a9c60228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the trained model\n",
    "model.save(\"Covid19_CNN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9394db47",
   "metadata": {},
   "source": [
    "### 9. Evaluating the model using testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96fd7109-11ae-4c26-9609-ac810789b1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 0.2256 - accuracy: 0.9375\n",
      "Test Loss: 0.22559314966201782\n",
      "Test Accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "# Assuming you've trained and saved your model in a variable named 'model'\n",
    "\n",
    "# Use the testing data (x_test, y_test) to evaluate the model\n",
    "evaluation = model.evaluate(x_test, y_test, batch_size=Batch_Size)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", evaluation[0])\n",
    "print(\"Test Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047fce1-a970-4dac-a904-a26ca8e6c9ae",
   "metadata": {},
   "source": [
    "evaluation[0] represents the test loss, and evaluation[1] represents the test accuracy. Here's what these values mean:\n",
    "\n",
    "evaluation[0]: This is the test loss, which quantifies how well the model's predictions match the true labels in the testing dataset. Lower values of the test loss indicate better performance, as it means the model's predictions are closer to the ground truth.\n",
    "\n",
    "evaluation[1]: This is the test accuracy, which is the proportion of correctly classified samples in the testing dataset. It is a common metric for classification tasks and represents the model's ability to make accurate predictions on unseen data. Higher accuracy values indicate better model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffefd2f",
   "metadata": {},
   "source": [
    "### 10. Evalating the model with new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "315cd7e4-5291-4034-85c6-9375ec1c076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 170ms/step\n",
      "Predicted Class: Covid\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the new image\n",
    "new_image_path = 'Covid19-dataset/test/Covid/0112.jpg'  # Replace with the path to your new image\n",
    "new_image = cv2.imread(new_image_path)\n",
    "new_image = cv2.resize(new_image, (500, 500))\n",
    "new_image = new_image / 255  # Normalize pixel values\n",
    "\n",
    "# Expand dimensions to match the model's input shape\n",
    "new_image = np.expand_dims(new_image, axis=0)\n",
    "\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(new_image)\n",
    "\n",
    "# Interpret the predictions\n",
    "class_index = np.argmax(predictions)  # Get the index of the class with the highest probability\n",
    "predicted_class = categories[class_index]  # Map the index to the class label\n",
    "\n",
    "# Print the predicted class\n",
    "print(\"Predicted Class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1232a",
   "metadata": {},
   "source": [
    "### 11. Evaluate the saved model with testing data (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb2c3c68-4eee-44fc-ada5-c85fd5ef0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 0.2256 - accuracy: 0.9375\n",
      "Test Loss: 0.22559314966201782\n",
      "Test Accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model(\"Covid19_CNN.h5\")\n",
    "\n",
    "# Evaluate the model with testing data (x_test, y_test)\n",
    "evaluation = loaded_model.evaluate(x_test, y_test, batch_size=Batch_Size)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Test Loss:\", evaluation[0])\n",
    "print(\"Test Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35498b52",
   "metadata": {},
   "source": [
    "### 12. Evaluate the saved model in new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b56acd22-e314-4517-afb4-9a7f4718df46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 136ms/step\n",
      "Predicted Class: Covid\n"
     ]
    }
   ],
   "source": [
    "### Use saved model to evaluate in new image\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model(\"Covid_CNN.h5\")\n",
    "\n",
    "# Preprocess a new image\n",
    "new_image_path = 'Covid19-dataset/test/Covid/0112.jpg'  # Replace with the path to your new image\n",
    "new_image = cv2.imread(new_image_path)\n",
    "new_image = cv2.resize(new_image, (500, 500))\n",
    "new_image = new_image / 255  # Normalize pixel values\n",
    "new_image = np.expand_dims(new_image, axis=0)  # Expand dimensions\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "predictions = loaded_model.predict(new_image)\n",
    "\n",
    "# Interpret the predictions (e.g., get the predicted class label)\n",
    "class_index = np.argmax(predictions)\n",
    "predicted_class = categories[class_index]\n",
    "print(\"Predicted Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9b7a4ef-50cd-4036-b107-9eeca94ca830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "Predicted Class: Viral Pneumonia\n"
     ]
    }
   ],
   "source": [
    "### Testing a model with another new image\n",
    "# Load the saved model\n",
    "loaded_model = load_model(\"Covid_CNN.h5\")\n",
    "\n",
    "# Preprocess a new image\n",
    "new_image_path = 'Covid19-dataset/test/Viral Pneumonia/0120.jpeg'  # Replace with the path to your new image\n",
    "new_image = cv2.imread(new_image_path)\n",
    "new_image = cv2.resize(new_image, (500, 500))\n",
    "new_image = new_image / 255  # Normalize pixel values\n",
    "new_image = np.expand_dims(new_image, axis=0)  # Expand dimensions\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "predictions = loaded_model.predict(new_image)\n",
    "\n",
    "# Interpret the predictions (e.g., get the predicted class label)\n",
    "class_index = np.argmax(predictions)\n",
    "predicted_class = categories[class_index]\n",
    "print(\"Predicted Class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e24dcd-dea6-46f2-b258-391bbc446ae7",
   "metadata": {},
   "source": [
    "### 13. Visulize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28c271a8-27d2-488c-b97d-cec10b497d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 images belonging to 3 classes.\n",
      "66/66 [==============================] - 5s 70ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Covid       1.00      0.96      0.98        26\n",
      "         Normal       0.95      1.00      0.98        20\n",
      "Viral Pneumonia       1.00      1.00      1.00        20\n",
      "\n",
      "       accuracy                           0.98        66\n",
      "      macro avg       0.98      0.99      0.99        66\n",
      "   weighted avg       0.99      0.98      0.98        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create a data generator for the test set\n",
    "test_data_generator = ImageDataGenerator(rescale=1.0/255.0)  # Rescale pixel values\n",
    "\n",
    "# Load the test data from the directories\n",
    "test_data = test_data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(500, 500),  # Adjust target size as needed\n",
    "    batch_size=1,  # Set batch size to 1 to visualize individual predictions\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important to match predictions with true labels\n",
    ")\n",
    "\n",
    "# Get true labels\n",
    "true_labels = test_data.classes\n",
    "\n",
    "# Predict using your VGG16 model\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions.argmax(axis=1))\n",
    "\n",
    "# Get class names (categories)\n",
    "class_names = list(test_data.class_indices.keys())\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(true_labels, predictions.argmax(axis=1), target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92335c92",
   "metadata": {},
   "source": [
    "### ....... Finished ........."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
